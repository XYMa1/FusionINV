#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
FusionINV æ‰¹é‡å¤„ç†è„šæœ¬
é€‚ç”¨äº LLVIP(50)ã€MSRS(361)ã€TNO(25) æ•°æ®é›†
"""

import os
import subprocess
from pathlib import Path
from tqdm import tqdm
import argparse
import time
import json

# æ•°æ®é›†é…ç½®
DATASETS = {
    'LLVIP': {
        'ir_dir': 'data/LLVIP/ir',
        'vi_dir': 'data/LLVIP/vi',
        'extensions': ['.jpg', '.JPG', '.jpeg', '. JPEG'],
        'count': 50
    },
    'MSRS': {
        'ir_dir': 'data/MSRS/ir',
        'vi_dir': 'data/MSRS/vi',
        'extensions': ['.png', '.PNG'],
        'count': 361
    },
    'TNO': {
        'ir_dir': 'data/TNO/ir',
        'vi_dir': 'data/TNO/vi',
        'extensions': ['.png', '.PNG'],
        'count': 25
    }
}


def find_matching_file(stem, directory, extensions):
    """åœ¨ç›®å½•ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶ï¼ˆä¸åŒºåˆ†å¤§å°å†™æ‰©å±•åï¼‰"""
    dir_path = Path(directory)
    for ext in extensions:
        candidate = dir_path / f"{stem}{ext}"
        if candidate.exists():
            return candidate
    return None


def get_image_pairs(dataset_name, config):
    """è·å–æ•°æ®é›†ä¸­çš„å›¾åƒå¯¹"""
    ir_dir = Path(config['ir_dir'])
    vi_dir = Path(config['vi_dir'])
    extensions = config['extensions']

    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not ir_dir.exists():
        print(f"âŒ çº¢å¤–æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {ir_dir}")
        return []
    if not vi_dir.exists():
        print(f"âŒ å¯è§å…‰æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {vi_dir}")
        return []

    # è·å–æ‰€æœ‰çº¢å¤–å›¾åƒ
    ir_images = []
    for ext in extensions:
        ir_images.extend(ir_dir.glob(f'*{ext}'))
    ir_images = sorted(ir_images)

    print(f"  æ‰¾åˆ° {len(ir_images)} å¼ çº¢å¤–å›¾åƒ")

    # åŒ¹é…å¯è§å…‰å›¾åƒ
    pairs = []
    unmatched = []

    for ir_path in ir_images:
        # æŸ¥æ‰¾åŒ¹é…çš„å¯è§å…‰å›¾åƒ
        vi_path = find_matching_file(ir_path.stem, vi_dir, extensions)

        if vi_path:
            pairs.append({
                'vi': str(vi_path),
                'ir': str(ir_path),
                'name': ir_path.stem,
                'dataset': dataset_name
            })
        else:
            unmatched.append(ir_path.name)

    print(f"  æˆåŠŸé…å¯¹: {len(pairs)} å¯¹")
    if unmatched:
        print(f"  âš ï¸ æœªé…å¯¹:  {len(unmatched)} ä¸ª")
        if len(unmatched) <= 5:
            for name in unmatched:
                print(f"    - {name}")

    return pairs


def check_if_processed(pair_info, output_base):
    """æ£€æŸ¥å›¾åƒå¯¹æ˜¯å¦å·²ç»å¤„ç†è¿‡"""
    dataset = pair_info['dataset']
    name = pair_info['name']

    # å¯èƒ½çš„è¾“å‡ºè·¯å¾„
    output_path = Path(output_base) / dataset / dataset / f"vis={name}---ir={name}" / "out_fusion---seed_41.png"

    return output_path.exists()


def process_single_pair(pair_info, output_base, skip_existing=True):
    """å¤„ç†å•å¯¹å›¾åƒ"""
    dataset = pair_info['dataset']
    name = pair_info['name']

    # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†
    if skip_existing and check_if_processed(pair_info, output_base):
        return {'status': 'skip', 'name': name, 'dataset': dataset}

    try:
        output_dir = Path(output_base) / dataset
        output_dir.mkdir(parents=True, exist_ok=True)

        # æ„å»ºå‘½ä»¤
        cmd = [
            'python', 'fusioninv.py',
            '--vis_image_path', pair_info['vi'],
            '--ir_image_path', pair_info['ir'],
            '--domain_name', dataset,
            '--output_path', str(output_dir),
            '--use_masked_adain', 'False',
            '--load_latents', 'True'
        ]

        # è¿è¡Œ
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )

        if result.returncode == 0:
            return {'status': 'success', 'name': name, 'dataset': dataset}
        else:
            return {
                'status': 'failed',
                'name': name,
                'dataset': dataset,
                'error': result.stderr[: 300]
            }

    except subprocess.TimeoutExpired:
        return {'status': 'timeout', 'name': name, 'dataset': dataset}
    except Exception as e:
        return {'status': 'error', 'name': name, 'dataset': dataset, 'error': str(e)}


def process_dataset(dataset_name, config, output_base, skip_existing=True):
    """å¤„ç†å•ä¸ªæ•°æ®é›†ï¼ˆé¡ºåºå¤„ç†ï¼‰"""
    print(f"\n{'=' * 70}")
    print(f"ğŸ“‚ å¤„ç†æ•°æ®é›†: {dataset_name}")
    print(f"{'=' * 70}")

    # è·å–å›¾åƒå¯¹
    pairs = get_image_pairs(dataset_name, config)

    if len(pairs) == 0:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°å›¾åƒå¯¹ï¼Œè·³è¿‡ {dataset_name}")
        return {'success': 0, 'failed': 0, 'skip': 0, 'timeout': 0, 'error': 0}

    # ç»Ÿè®¡ç»“æœ
    results = {'success': 0, 'failed': 0, 'skip': 0, 'timeout': 0, 'error': 0}
    failed_items = []

    # å¤„ç†æ¯å¯¹å›¾åƒ
    for pair in tqdm(pairs, desc=f"å¤„ç† {dataset_name}", unit="å¯¹"):
        result = process_single_pair(pair, output_base, skip_existing)
        results[result['status']] += 1

        if result['status'] in ['failed', 'error']:
            failed_items.append(result)
            tqdm.write(f"  âŒ å¤±è´¥: {result['name']}")
            if 'error' in result:
                tqdm.write(f"     é”™è¯¯: {result['error'][: 150]}")
        elif result['status'] == 'timeout':
            failed_items.append(result)
            tqdm.write(f"  â±ï¸ è¶…æ—¶: {result['name']}")

    # æ‰“å°ç»“æœ
    print(f"\nğŸ“Š {dataset_name} å¤„ç†ç»“æœ:")
    print(f"  âœ… æˆåŠŸ: {results['success']}")
    print(f"  â­ï¸ è·³è¿‡(å·²å­˜åœ¨): {results['skip']}")
    print(f"  âŒ å¤±è´¥: {results['failed']}")
    print(f"  â±ï¸ è¶…æ—¶: {results['timeout']}")
    print(f"  â— é”™è¯¯: {results['error']}")

    # ä¿å­˜å¤±è´¥åˆ—è¡¨
    if failed_items:
        failed_file = Path(output_base) / f"{dataset_name}_failed.json"
        with open(failed_file, 'w', encoding='utf-8') as f:
            json.dump(failed_items, f, indent=2, ensure_ascii=False)
        print(f"  ğŸ“„ å¤±è´¥åˆ—è¡¨å·²ä¿å­˜: {failed_file}")

    return results


def main():
    parser = argparse.ArgumentParser(
        description='FusionINV æ‰¹é‡å¤„ç†è„šæœ¬ - LLVIP(50), MSRS(361), TNO(25)',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        '--datasets',
        nargs='+',
        choices=list(DATASETS.keys()) + ['all'],
        default=['all'],
        help='è¦å¤„ç†çš„æ•°æ®é›† (é»˜è®¤: all)'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='output',
        help='è¾“å‡ºæ ¹ç›®å½• (é»˜è®¤: output)'
    )
    parser.add_argument(
        '--skip-existing',
        action='store_true',
        default=True,
        help='è·³è¿‡å·²ç»å¤„ç†è¿‡çš„å›¾åƒ (é»˜è®¤: True)'
    )
    parser.add_argument(
        '--no-skip',
        action='store_true',
        help='é‡æ–°å¤„ç†æ‰€æœ‰å›¾åƒï¼ˆä¸è·³è¿‡å·²å­˜åœ¨çš„ï¼‰'
    )

    args = parser.parse_args()

    # å¤„ç†è·³è¿‡é€‰é¡¹
    skip_existing = not args.no_skip

    print("ğŸš€ FusionINV æ‰¹é‡å¤„ç†å·¥å…·")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}/")
    print(f"â­ï¸ è·³è¿‡å·²å¤„ç†: {'æ˜¯' if skip_existing else 'å¦'}")
    print(f"ğŸ–¥ï¸ GPU:  RTX 4090 D")

    # ç¡®å®šè¦å¤„ç†çš„æ•°æ®é›†
    if 'all' in args.datasets:
        datasets_to_process = list(DATASETS.keys())
    else:
        datasets_to_process = args.datasets

    # ç»Ÿè®¡æ€»æ•°
    total_pairs = sum(DATASETS[name]['count'] for name in datasets_to_process)
    print(f"ğŸ“Š é¢„è®¡å¤„ç†:  {len(datasets_to_process)} ä¸ªæ•°æ®é›†, å…± {total_pairs} å¯¹å›¾åƒ")

    # ä¼°ç®—æ—¶é—´
    estimated_time = total_pairs * 1  # å‡è®¾æ¯å¯¹1åˆ†é’Ÿ
    print(f"â±ï¸ é¢„è®¡è€—æ—¶: {estimated_time // 60}å°æ—¶{estimated_time % 60}åˆ†é’Ÿ (é¡ºåºå¤„ç†)")
    print()

    # å¼€å§‹å¤„ç†
    start_time = time.time()
    overall_results = {'success': 0, 'failed': 0, 'skip': 0, 'timeout': 0, 'error': 0}

    for dataset_name in datasets_to_process:
        if dataset_name in DATASETS:
            results = process_dataset(
                dataset_name,
                DATASETS[dataset_name],
                args.output,
                skip_existing
            )

            # ç´¯åŠ ç»“æœ
            for key in overall_results:
                overall_results[key] += results[key]

    # è®¡ç®—æ€»è€—æ—¶
    elapsed_time = time.time() - start_time
    hours = int(elapsed_time // 3600)
    minutes = int((elapsed_time % 3600) // 60)
    seconds = int(elapsed_time % 60)

    # æ‰“å°æ€»ç»“
    print(f"\n{'=' * 70}")
    print("ğŸ‰ æ‰€æœ‰æ•°æ®é›†å¤„ç†å®Œæˆï¼")
    print(f"{'=' * 70}")
    print(f"ğŸ“Š æ€»ä½“ç»“æœ:")
    print(f"  âœ… æˆåŠŸ: {overall_results['success']}")
    print(f"  â­ï¸ è·³è¿‡:  {overall_results['skip']}")
    print(f"  âŒ å¤±è´¥: {overall_results['failed']}")
    print(f"  â±ï¸ è¶…æ—¶:  {overall_results['timeout']}")
    print(f"  â— é”™è¯¯: {overall_results['error']}")
    print(f"\nâ±ï¸ æ€»è€—æ—¶:  {hours}å°æ—¶{minutes}åˆ†é’Ÿ{seconds}ç§’")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.output}/")
    print(f"{'=' * 70}")


if __name__ == '__main__':
    main()
