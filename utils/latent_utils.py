from pathlib import Path
from typing import Tuple

import numpy as np
import torch
from PIL import Image
from diffusers.training_utils import set_seed

from AllinVIS import AllinVISModel
from config import RunConfig
from utils import image_utils
from utils.ddpm_inversion_vis import invert
from utils.ddpm_inversion_inf2vis import invertinf
# åœ¨ç°æœ‰ import åæ·»åŠ 
from utils.low_light_enhance import enhance_low_light
from utils.exposure_metrics import compute_exposure


def load_latents_or_invert_images(model: AllinVISModel, cfg: RunConfig):
    if cfg.load_latents and cfg.vis_latent_save_path.exists() and cfg.ir_latent_save_path.exists():
        print("Loading existing latents...")
        latents_vis, latents_ir = load_latents(cfg.vis_latent_save_path, cfg.ir_latent_save_path)
        noise_vis, noise_ir = load_noise(cfg.vis_latent_save_path, cfg.ir_latent_save_path)
        print("Done.")
    else:
        print("Inverting images...")
        vis_image, ir_image = image_utils.load_images(cfg=cfg, save_path=cfg.output_path)
        model.enable_edit = False  # Deactivate the cross-image attention layers
        latents_vis, latents_ir, noise_vis, noise_ir = invert_images(vis_image=vis_image,
                                                                             ir_image=ir_image,
                                                                             sd_model=model.pipe,
                                                                             cfg=cfg)
        model.enable_edit = True
        print("Done.")
    return latents_vis, latents_ir, noise_vis, noise_ir


def load_latents(vis_latent_save_path: Path, ir_latent_save_path: Path) -> Tuple[torch.Tensor, torch.Tensor]:
    latents_vis = torch.load(vis_latent_save_path)
    latents_ir = torch.load(ir_latent_save_path)
    if type(latents_ir) == list:
        latents_vis = [l.to("cuda") for l in latents_vis]
        latents_ir = [l.to("cuda") for l in latents_ir]
    else:
        latents_vis = latents_vis.to("cuda")
        latents_ir = latents_ir.to("cuda")
    return latents_vis, latents_ir


def load_noise(vis_latent_save_path: Path, ir_latent_save_path: Path) -> Tuple[torch.Tensor, torch.Tensor]:
    latents_vis = torch.load(vis_latent_save_path.parent / (vis_latent_save_path.stem + "_ddpm_noise.pt"))
    latents_ir = torch.load(ir_latent_save_path.parent / (ir_latent_save_path.stem + "_ddpm_noise.pt"))
    latents_vis = latents_vis.to("cuda")
    latents_ir = latents_ir.to("cuda")
    return latents_vis, latents_ir


def invert_images(sd_model, vis_image: Image.Image, ir_image: Image.Image, cfg: RunConfig):
    """
    æ”¹è¿›çš„å›¾åƒåæ¼”æµç¨‹ï¼šé›†æˆä½å…‰å¢å¼º + åŠ¨æ€Prompt
    """
    print("\n" + "=" * 70)
    print("ğŸ”„ å¼€å§‹å›¾åƒåæ¼” (DDPM Inversion)")
    print("=" * 70)

    # ========== å¯è§å…‰è·¯ï¼šå¢å¼º + åæ¼” ==========
    print("\n[é˜¶æ®µ 1] å¯è§å…‰å›¾åƒé¢„å¤„ç†")

    # 1. è®¡ç®—åŸå§‹æ›å…‰åº¦
    vis_np = np.array(vis_image)
    from utils.exposure_metrics import compute_exposure, generate_dynamic_prompt
    E_vi = compute_exposure(vis_np)
    print(f"  ğŸ“Š åŸå§‹æ›å…‰åº¦:  E_vi = {E_vi:. 4f}")

    # 2. ä½å…‰å¢å¼ºï¼ˆå¦‚æœéœ€è¦ï¼‰
    if E_vi < 0.15:
        # ææš—åœºæ™¯ï¼šè·³è¿‡å¢å¼ºä»¥ä¿ç•™ç»†èŠ‚
        print(f"  âš ï¸  åœºæ™¯ææš— (E_vi={E_vi:.3f})ï¼Œè·³è¿‡å¢å¼ºä»¥ä¿ç•™ç»†èŠ‚")
        vis_enhanced_np = vis_np
    elif E_vi < 0.6:
        # å¼±å…‰åœºæ™¯ï¼šæ‰§è¡Œå¢å¼º
        print(f"  ğŸ”§ æ£€æµ‹åˆ°ä½å…‰åœºæ™¯ï¼Œæ‰§è¡Œ Retinex å¢å¼º...")
        from utils.low_light_enhance import enhance_low_light
        vis_enhanced_np = enhance_low_light(vis_np, exposure=E_vi)
        vis_enhanced = Image.fromarray(vis_enhanced_np)

        # ä¿å­˜å¢å¼ºåçš„å›¾åƒï¼ˆç”¨äºè°ƒè¯•ï¼‰
        if cfg.output_path:
            vis_enhanced.save(cfg.output_path / "vi_enhanced.png")
            print(f"  âœ… å¢å¼ºå›¾åƒå·²ä¿å­˜:  vi_enhanced.png")
    else:
        # å…‰ç…§å……è¶³ï¼šè·³è¿‡å¢å¼º
        print(f"  âœ… å…‰ç…§å……è¶³ï¼Œè·³è¿‡å¢å¼º")
        vis_enhanced_np = vis_np

    # 3. ç”ŸæˆåŠ¨æ€Promptï¼ˆæ”¹è¿›ç‰ˆ - æ”¯æŒNegativeï¼‰
    positive_prompt, negative_prompt = generate_dynamic_prompt(E_vi)

    if positive_prompt:
        print(f"  ğŸ“ åŠ¨æ€Prompt (Positive): \"{positive_prompt}\"")
        print(f"  ğŸ“ åŠ¨æ€Prompt (Negative): \"{negative_prompt}\"")
    else:
        print(f"  ğŸ“ ä½¿ç”¨ç©ºPromptï¼ˆåœºæ™¯å…‰ç…§æ­£å¸¸ï¼‰")

    # 4. è½¬æ¢ä¸º tensor
    input_vis = torch.from_numpy(vis_enhanced_np).float() / 127.5 - 1.0
    input_vis = input_vis.permute(2, 0, 1).unsqueeze(0).to('cuda')

    # 5. DDPM Inversionï¼ˆVIè·¯ï¼‰
    print(f"  ğŸ”„ æ‰§è¡Œ DDPM Inversion (VIè·¯)...")
    set_seed(cfg.seed)

    # ã€å…³é”®ä¿®æ”¹ã€‘ä½¿ç”¨åŠ¨æ€Promptå’Œæ›´é«˜çš„CFG
    from utils.ddpm_inversion_vis import invert
    zs_vis, latents_vis, directions = invert(
        x0=input_vis,
        pipe=sd_model,
        prompt_src=positive_prompt,  # ä½¿ç”¨åŠ¨æ€Prompt
        num_diffusion_steps=cfg.num_timesteps,
        cfg_scale_src=5.5 if E_vi < 0.3 else 3.5,  # ä½å…‰åœºæ™¯æé«˜CFG
        eta=1,
        use_dynamic_prompt=False,  # å·²ç»æ‰‹åŠ¨ç”Ÿæˆäº†
        exposure=E_vi
    )

    # ========== çº¢å¤–è·¯ï¼šæ ‡å‡†åæ¼” ==========
    print("\n[é˜¶æ®µ 2] çº¢å¤–å›¾åƒåæ¼”")
    input_ir = torch.from_numpy(np.array(ir_image)).float() / 127.5 - 1.0
    input_ir = input_ir.permute(2, 0, 1).unsqueeze(0).to('cuda')

    set_seed(cfg.seed)
    from utils.ddpm_inversion_inf2vis import invertinf
    direction_step_size = float(cfg.direction_step_size)

    print(f"  ğŸ”„ æ‰§è¡Œ DDPM Inversion (IRè·¯)...")
    zs_ir, latents_ir = invertinf(
        x0=input_ir,
        vis_direction=directions,
        direction_step_size=direction_step_size,
        pipe=sd_model,
        num_diffusion_steps=cfg.num_timesteps,
        cfg_scale_src=3.5
    )

    # ========== ä¿å­˜ latentsï¼ˆå¯é€‰ï¼‰==========
    if not cfg.load_latents:
        print(f"\nğŸ’¾ ä¿å­˜ Latents åˆ° {cfg.latents_path}")
        torch.save(latents_vis, cfg.latents_path / f"{cfg.vis_image_path.stem}_vis.pt")
        torch.save(latents_ir, cfg.latents_path / f"{cfg.ir_image_path.stem}_ir.pt")
        torch.save(zs_vis, cfg.latents_path / f"{cfg.vis_image_path.stem}_vis_ddpm_noise.pt")
        torch.save(zs_ir, cfg.latents_path / f"{cfg.ir_image_path.stem}_ir_ddpm_noise. pt")

    # ========== ä¿å­˜æ›å…‰åº¦ä¿¡æ¯ï¼ˆä¾›åç»­ä½¿ç”¨ï¼‰==========
    cfg.E_vi = E_vi

    # è½¬æ¢æ ¼å¼
    if isinstance(zs_ir, list):
        zs_ir = torch.stack(zs_ir)
    if isinstance(latents_ir, list):
        latents_ir = torch.stack(latents_ir)

    print("\n" + "=" * 70)
    print(f"âœ… åæ¼”å®Œæˆ (E_vi={E_vi:.4f})")
    print("=" * 70 + "\n")

    return latents_vis, latents_ir, zs_vis, zs_ir


def get_init_latents_and_noises(model: AllinVISModel, cfg: RunConfig) -> Tuple[torch.Tensor, torch.Tensor]:
    # If we stored all the latents along the diffusion process, select the desired one based on the skip_steps
    if model.latents_ir.dim() == 4 and model.latents_vis.dim() == 4 and model.latents_vis.shape[0] > 1:
        model.latents_ir = model.latents_ir[cfg.skip_steps]
        model.latents_vis = model.latents_vis[cfg.skip_steps]
    init_latents = torch.stack([model.latents_vis, model.latents_vis, model.latents_ir])
    zs_fusion = model.zs_vis.clone()
    init_zs = [ zs_fusion[cfg.skip_steps:], model.zs_vis[cfg.skip_steps:], model.zs_ir[cfg.skip_steps:]]
    return init_latents, init_zs
