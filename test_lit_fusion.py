"""
LIT-Fusion ç«¯åˆ°ç«¯æµ‹è¯•è„šæœ¬
æµ‹è¯•å®Œæ•´çš„ä½å…‰ç…§èåˆæµç¨‹
"""

import sys

sys.path.append(".")

from pathlib import Path
import torch
import numpy as np
from PIL import Image

from config import RunConfig
from AllinVIS import AllinVISModel
from utils.latent_utils import load_latents_or_invert_images
from utils.exposure_metrics import compute_exposure, get_illumination_level


def create_test_images():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ä½å…‰å›¾åƒï¼ˆå¦‚æœæ²¡æœ‰çœŸå®æ•°æ®ï¼‰"""
    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„ä½å…‰å¯è§å…‰å›¾åƒ
    vi_image = np.ones((512, 512, 3), dtype=np.uint8) * 30  # å¾ˆæš—
    vi_image[100:200, 100:200] = [50, 50, 60]  # æ·»åŠ ä¸€äº›ç»†èŠ‚

    # åˆ›å»ºä¸€ä¸ªæ¨¡æ‹Ÿçš„çº¢å¤–å›¾åƒ
    ir_image = np.ones((512, 512, 3), dtype=np.uint8) * 128
    ir_image[150:250, 150:250] = 200  # çƒ­ç›®æ ‡

    # ä¿å­˜
    output_dir = Path("data/test")
    output_dir.mkdir(parents=True, exist_ok=True)

    Image.fromarray(vi_image).save(output_dir / "test_vi_lowlight.png")
    Image.fromarray(ir_image).save(output_dir / "test_ir. png")

    print(f"âœ… æµ‹è¯•å›¾åƒå·²åˆ›å»º: {output_dir}")
    return output_dir / "test_vi_lowlight. png", output_dir / "test_ir.png"


def test_exposure_calculation():
    """æµ‹è¯•æ›å…‰åº¦è®¡ç®—"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 1: æ›å…‰åº¦è®¡ç®—")
    print("=" * 60)

    # åˆ›å»ºä¸åŒäº®åº¦çš„æµ‹è¯•å›¾åƒ
    test_cases = [
        ("ææš—", np.ones((100, 100, 3), dtype=np.uint8) * 20),
        ("å¾ˆæš—", np.ones((100, 100, 3), dtype=np.uint8) * 50),
        ("å¼±å…‰", np.ones((100, 100, 3), dtype=np.uint8) * 100),
        ("æ­£å¸¸", np.ones((100, 100, 3), dtype=np.uint8) * 150),
    ]

    for name, img in test_cases:
        E_vi = compute_exposure(img)
        level = get_illumination_level(E_vi)
        print(f"  {name}: E_vi={E_vi:.4f}, ç­‰çº§={level}")

    print("âœ… æ›å…‰åº¦è®¡ç®—æµ‹è¯•é€šè¿‡")


def test_model_initialization():
    """æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 2: æ¨¡å‹åˆå§‹åŒ–")
    print("=" * 60)

    vi_path, ir_path = create_test_images()

    cfg = RunConfig(
        vis_image_path=vi_path,
        ir_image_path=ir_path,
        domain_name="test_lowlight",
        num_timesteps=50,
        use_masked_adain=False,
        load_latents=False,  # å¼ºåˆ¶é‡æ–°åæ¼”
        skip_steps=16  # å‡å°‘æ­¥æ•°åŠ å¿«æµ‹è¯•
    )

    try:
        model = AllinVISModel(cfg)
        print(f"  âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸ")
        print(f"  - total_steps: {model.total_steps}")
        print(f"  - E_vi (åˆå§‹): {model.E_vi}")
        print(f"  - enable_edit: {model.enable_edit}")

        # æµ‹è¯•æƒé‡è®¡ç®—
        print("\n  æµ‹è¯•æƒé‡è®¡ç®—:")
        for step in [0, 25, 45]:
            current_t = model.total_steps - step
            w1, w2, w3 = model.compute_adaptive_weights(current_t)
            print(f"    step={step}, t={current_t}:  w_ir={w1:.3f}, w_vi={w2:.3f}, w_txt={w3:.3f}")

        print("âœ… æ¨¡å‹åˆå§‹åŒ–æµ‹è¯•é€šè¿‡")
        return model, cfg

    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def test_inversion(model, cfg):
    """æµ‹è¯•åæ¼”æµç¨‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 3: å›¾åƒåæ¼”ï¼ˆå«å¢å¼ºï¼‰")
    print("=" * 60)

    try:
        latents_vis, latents_ir, noise_vis, noise_ir = load_latents_or_invert_images(
            model=model,
            cfg=cfg
        )

        print(f"  âœ… åæ¼”å®Œæˆ")
        print(f"  - latents_vis shape: {latents_vis.shape}")
        print(f"  - latents_ir shape: {latents_ir.shape}")
        print(f"  - æ›å…‰åº¦ E_vi: {cfg.E_vi:. 4f}")

        # æ›´æ–°æ¨¡å‹çš„æ›å…‰åº¦
        model.E_vi = cfg.E_vi
        model.set_latents(latents_vis, latents_ir)
        model.set_noise(noise_vis, noise_ir)

        print("âœ… åæ¼”æµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ åæ¼”å¤±è´¥:  {e}")
        import traceback
        traceback.print_exc()
        return False


def test_fusion(model, cfg):
    """æµ‹è¯•èåˆæµç¨‹"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• 4: ç«¯åˆ°ç«¯èåˆ")
    print("=" * 60)

    try:
        from utils.latent_utils import get_init_latents_and_noises
        from config import Range

        init_latents, init_zs = get_init_latents_and_noises(model=model, cfg=cfg)
        model.pipe.scheduler.set_timesteps(cfg.num_timesteps)
        model.enable_edit = True

        print(f"  å¼€å§‹èåˆï¼ˆ{cfg.num_timesteps - cfg.skip_steps} æ­¥ï¼‰...")

        visir_prompts = [cfg.prompt, "", ""]

        images = model.pipe(
            prompt=visir_prompts,
            latents=init_latents,
            guidance_scale=cfg.swap_guidance_scale,
            num_inference_steps=cfg.num_timesteps,
            swap_guidance_scale=cfg.swap_guidance_scale,
            callback=model.get_adain_callback(),
            eta=1,
            zs=init_zs,
            generator=torch.Generator('cuda').manual_seed(cfg.seed),
            cross_image_attention_range=Range(start=1, end=90),
        ).images

        # ä¿å­˜ç»“æœ
        images[0].save(cfg.output_path / "test_fusion. png")
        images[1].save(cfg.output_path / "test_vis.png")
        images[2].save(cfg.output_path / "test_ir.png")

        print(f"  âœ… èåˆå®Œæˆ")
        print(f"  - ç»“æœä¿å­˜è‡³: {cfg.output_path}")
        print(f"  - èåˆå›¾åƒ:  test_fusion.png")

        print("âœ… èåˆæµ‹è¯•é€šè¿‡")
        return True

    except Exception as e:
        print(f"âŒ èåˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print("\n" + "ğŸš€" * 30)
    print("LIT-Fusion ç«¯åˆ°ç«¯æµ‹è¯•")
    print("ğŸš€" * 30)

    # æµ‹è¯• 1: æ›å…‰åº¦è®¡ç®—
    test_exposure_calculation()

    # æµ‹è¯• 2: æ¨¡å‹åˆå§‹åŒ–
    model, cfg = test_model_initialization()
    if model is None:
        print("\nâŒ æµ‹è¯•ä¸­æ­¢ï¼šæ¨¡å‹åˆå§‹åŒ–å¤±è´¥")
        return

    # æµ‹è¯• 3: åæ¼”
    if not test_inversion(model, cfg):
        print("\nâŒ æµ‹è¯•ä¸­æ­¢ï¼šåæ¼”å¤±è´¥")
        return

    # æµ‹è¯• 4: èåˆ
    if not test_fusion(model, cfg):
        print("\nâŒ æµ‹è¯•ä¸­æ­¢ï¼šèåˆå¤±è´¥")
        return

    # å…¨éƒ¨é€šè¿‡
    print("\n" + "ğŸ‰" * 30)
    print("æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼LIT-Fusion å·²æˆåŠŸéƒ¨ç½²ï¼")
    print("ğŸ‰" * 30)
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("  1. ä½¿ç”¨çœŸå®çš„ä½å…‰å›¾åƒæµ‹è¯•")
    print("  2. è¿è¡Œæ‰¹é‡æµ‹è¯•è„šæœ¬")
    print("  3. è°ƒæ•´å‚æ•°ä¼˜åŒ–ç»“æœ")


if __name__ == "__main__":
    # è®¾ç½®è®¾å¤‡
    import torch

    if torch.cuda.is_available():
        print(f"âœ… CUDA å¯ç”¨: {torch.cuda.get_device_name(0)}")
    else:
        print("âš ï¸  CUDA ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ CPUï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")

    main()
