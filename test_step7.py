"""æµ‹è¯•ä¿®æ­£åçš„ Step 7"""
import torch
from config import RunConfig
from AllinVIS import AllinVISModel
from pathlib import Path

# åˆ›å»ºé…ç½®
cfg = RunConfig(
    vis_image_path=Path("data/test_vi.png"),
    ir_image_path=Path("data/test_ir.png"),
    domain_name="test",
    num_timesteps=50  # è®¾ç½®50æ­¥
)

try:
    model = AllinVISModel(cfg)
    print(f"âœ… æ¨¡å‹åˆ›å»ºæˆåŠŸï¼Œtotal_steps={model.total_steps}")
    
    # è®¾ç½®æ›å…‰åº¦
    model.E_vi = 0.25
    print(f"âœ… æ›å…‰åº¦è®¾ç½®:  E_vi={model.E_vi}")
    
    # æµ‹è¯•æƒé‡è®¡ç®—ï¼ˆæ¨¡æ‹Ÿå»å™ªè¿‡ç¨‹ï¼‰
    print("\næƒé‡è®¡ç®—æµ‹è¯•ï¼ˆæ¨¡æ‹Ÿå»å™ªï¼‰:")
    print("step | current_t | t_norm | w_ir  | w_vi  | w_txt | é˜¶æ®µ")
    print("-" * 65)
    
    for step in [0, 10, 25, 40, 48]: 
        current_timestep = model.total_steps - step  # âœ… ä¿®æ­£åçš„è®¡ç®—
        w1, w2, w3 = model.compute_adaptive_weights(current_timestep)
        t_norm = current_timestep / model.total_steps
        
        if t_norm > 0.7:
            stage = "Early(å¼ºIR)"
        elif t_norm > 0.2:
            stage = "Mid(è¿‡æ¸¡)"
        else:
            stage = "Late(å¼ºVI)"
        
        print(f"{step:4d} | {current_timestep:9d} | {t_norm: 6.2f} | {w1:.3f} | {w2:.3f} | {w3:.3f} | {stage}")
    
    print("\nğŸ‰ ä¿®æ­£åçš„ Step 7 æµ‹è¯•é€šè¿‡ï¼")
    
except Exception as e:
    print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
